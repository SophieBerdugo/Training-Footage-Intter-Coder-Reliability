---
title: "ZD Training Footage Inter-Coder Reliability"
author: "Sophie Berdugo"
date: "16/04/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Video UID: f1acdcbb-c0d2-4a5d-98e4-e6d5986f15e1
### Video Observation Date: 2012-02-02 | Video Observation Time: 15:58:34

**Rater 1: Sophie Berdugo**
**Rater 2: Zhangzhuoran Dai**

Load libraries for analysis
```{r message=FALSE, warning=FALSE}
library(tidyverse) #Load tidyverse to use the tidyverse package
library(irr) #Load the irr package to retrieve packages relating to inter-rater reliability.
```

# Variables
This analysis involves establishing the levels of inter-rater reliability for various variables relating to adult nut-cracking efficiency and model investment. These variables are:

* Bout outcome
* Strikes per nut
* Displacement rate
* Tool switch rate
* Bout duration
* Average strike duration
* Learner
* Maternal model
* Learner name
* Model tolerance
* Model intolerance

The inter-rater reliability analysis utilised depends on the level of measurement of each variable under investigation. The levels of measurement and corresponding test of inter rater reliability for each variable can be found in Table 1, below:

*Table 1*

| Variable                | Level of Measurement | Approach                           |
| :---------------------- | :------------------- | :--------------------------------- |
| Bout outcome            | Nominal              | Cohen's kappa                      |
| Learner                 | Nominal              | Cohen's kappa                      |
| Maternal model          | Nominal              | Cohen's kappa                      |
| Learner name            | Nominal              | Cohen's kappa                      |
| Model tolerance         | Nominal              | Cohen's kappa                      |
| Model intolerance       | Nominal              | Cohen's kappa                      |
| Strikes per nut         | Ratio                | Intraclass correlation coefficient |
| Displacement rate       | Ratio                | Intraclass correlation coefficient |
| Tool switch rate        | Ratio                | Intraclass correlation coefficient |
| Bout duration           | Ratio                | Intraclass correlation coefficient |
| Average strike duration | Ratio                | Intraclass correlation coefficient |

### Bout outcome

The three potential bout outcomes are:

1. *Successful* - The nut is cracked open using the hammer and anvil composite and the full kernel is retrieved and eaten by an individual (not necessarily by focal subject, if kernel is scrounged). 
2. *Smash* - The nut is cracked open using hammer and anvil, but the kernel is smashed into multiple pieces and each piece is eaten separately.
3. *Failed* - A different nut is placed on the anvil following displacement of the original nut; or, the nut is not retrieved or not eaten by any individual. 

This data is nominal so an unweighted Cohen's kappa will be used to establish the concordance between two independent observers. 
rater1 = SB, rater2 = ZD

Import data frame as csv file.
```{r message=FALSE, warning=FALSE}
library(tidyverse)
bout_outcome <- read_csv("~/Documents/Oxford/DPhil/Project Components/Inter-Coder Reliability/Data/Zhangzhuoran Dai/Training Data/Individual variable data/Bout outcome.csv")
bout_outcome
```
Calculate Cohen's kappa for two coders.
?kappa2
```{r}
kappa2(bout_outcome[,c(1,2)], "unweighted")
```

**The agreement between the two raters was substantial, κ = 0.73, and greater than would be expected by chance,** ***Z*** **= 5.81,** ***p*** **< .05**

### Learner

The *learner* variable describes whether or not there was a conspecific who was present during the focal individual's nut-cracking bout. The three options for coding were:

1. *Watching* - There is a learner watching the focal subject during the nut-cracking bout, whereby the learner’s face is oriented toward the model’s hand or arm during the bout.
2. *Interacting* - There is a learner present, and they are interacting with the focal subject (for example, touching arm or body of model, climbing on model).
3. *Solo* - There is no learner with the focal individual during their nut-cracking bout.

This data is nominal so an unweighted Cohen's kappa will be used to establish the concordance between two independent observers. 
rater1 = SB, rater2 = ZD


Import data frame as csv file.
```{r message=FALSE, warning=FALSE}
learner <- read_csv("~/Documents/Oxford/DPhil/Project Components/Inter-Coder Reliability/Data/Zhangzhuoran Dai/Training Data/Individual variable data/Learner.csv")
learner
```

Calculate Cohen's kappa for two coders.
```{r}
kappa2(learner[,c(1,2)], "unweighted")
```
**The agreement between the two raters was almost perfect, κ = 0.932, and greater than would be expected by chance,** ***Z*** **= 7.91,** ***p*** **< .05**

### Maternal model

The *maternal model* variable describes whether the model is the learner's mother or not. The three options for coding are:

1. *Yes*
2. *No*
3. *None* - recorded if no learner was present

This data is nominal so an unweighted Cohen's kappa will be used to establish the concordance between two independent observers. 
rater1 = SB, rater2 = ZD

Import data frame from csv file
```{r message=FALSE, warning=FALSE}
maternal_model <- read_csv("~/Documents/Oxford/DPhil/Project Components/Inter-Coder Reliability/Data/Zhangzhuoran Dai/Training Data/Individual variable data/Maternal model.csv")
maternal_model
```

Calculate Cohen's kappa for two coders.
```{r}
kappa2(maternal_model[,c(1,2)], "unweighted")
```
**The agreement between the two raters was almost perfect, κ = 0.93, and greater than would be expected by chance,** ***Z*** **= 6.85,** ***p*** **< .05**

### Learner name

The *learner name* variable records the name of the learner if one is present in the bout. 'The coding options for the variable are the names 'None' is recorded if no learner was present.

This data is nominal so an unweighted Cohen's kappa will be used to establish the concordance between two independent observers. 
rater1 = SB, rater2 = ZD

Import data frame from csv file
```{r message=FALSE, warning=FALSE}
learner_name <- read_csv("~/Documents/Oxford/DPhil/Project Components/Inter-Coder Reliability/Data/Zhangzhuoran Dai/Training Data/Individual variable data/Learner name.csv")
learner_name
```
Calculate Cohen's kappa for two coders.
```{r}
kappa2(learner_name[,c(1,2)], "unweighted")
```
**The agreement between the two raters was almost perfect, κ = 0.932, and greater than would be expected by chance,** ***Z*** **= 7.91,** ***p*** **< .05**

### Model tolerance

The variable *model tolerance* is a record of whether the focal subject permitted any of the following learner behaviours during their nut-cracking bout:

1. *None* - No learner attempted to scrounge the kernel, interact with the model or the model’s tools or be proximate to the model during the nut-cracking bout.
2. *Scrounge* -	The focal chimpanzee permitted the learner to take the extracted kernel to eat themselves.
3. *Tool interaction* -	The focal chimpanzee permitted the learner to touch either one or both stones in the tool composite during the nut-cracking bout.
4. *Model interaction* - The focal chimpanzee permitted the learner to interact with them (for example, touching arm or body of model, climbing on model) during their nut-cracking bout.
5. *Tool re-use* - The focal chimpanzee permitted the learner to re-use one or both of their tool composite tools after their nut-cracking bout. 
6. *Proximity* - The focal chimpanzee permitted the learner to be ≤ 1 metre (m) away from them during the bout. In this case, the learner was not interacting with the focal subject, but was merely close to the focal subject and watching the nut-cracking bout.

This data is nominal so an unweighted Cohen's kappa will be used to establish the concordance between two independent observers. 
rater1 = SB, rater2 = ZD

Import data frame from csv file
```{r message=FALSE, warning=FALSE}
model_tolerance <- read_csv("~/Documents/Oxford/DPhil/Project Components/Inter-Coder Reliability/Data/Zhangzhuoran Dai/Training Data/Individual variable data/Model tolerance.csv")
model_tolerance
```

Calculate Cohen's kappa for two coders.
```{r}
kappa2(model_tolerance[,c(1,2)], "unweighted")
```
**The agreement between the two raters was almost perfect, κ = 0.856, and greater than would be expected by chance,** ***Z*** **= 7.06,** ***p*** **< .05**

### Model intolerance

The variable *model intolerance* is a record of whether the focal subject expressed intolerance toward a learner. The possible behaviours are:

1. *None* -	The focal subject did not express intolerance toward a learner during the bout.
2. *Physical* -	The focal subject physically rejected a learner’s attempts to scrounge, interact with the model or the tools, or be proximate whilst they were nut-cracking (for example, shoving, hitting, or chasing the learner).
3. *Vocal* -	The focal subject vocally rejected a learner’s attempts to scrounge, interact with the model or the tools, or be proximate whilst they are nut-cracking (for example, grunting, barking or screaming). Barking sounds like ‘waa’, ‘waaoo’ or ‘aaoo’, and are shorter than screams (Crockford & Boesch, 2003, p. 117).

This data is nominal so an unweighted Cohen's kappa will be used to establish the concordance between two independent observers. 
rater1 = SB, rater2 = ZD

Import data frame from csv file
```{r message=FALSE, warning=FALSE}
model_intolerance <- read_csv("~/Documents/Oxford/DPhil/Project Components/Inter-Coder Reliability/Data/Zhangzhuoran Dai/Training Data/Individual variable data/Model intolerance.csv")
model_intolerance
```

Calculate Cohen's kappa for two coders.
```{r}
kappa2(model_intolerance[,c(1,2)], "unweighted")
```
**The agreement between the two raters was perfect, κ = 1. Kappa = NaN because the formula is 0/0**

### Number of strikes

The variable *number of strikes* records the number of strikes performed by the focal individual on a nut in the whole nut-cracking bout. This is an exact number that is manually inputted by the coder. 

This data is ratio, and so intraclass correlations (ICC) will be used to establish the reliability between two independent coders. In accordance with Koo & Li's (2016) guidelines on ICC model selection, the method used here will be a two-way, mixed-effects, single rater absolute agreement ICC.

Import data frame from csv file
```{r message=FALSE, warning=FALSE}
number_of_strikes <- read_csv("~/Documents/Oxford/DPhil/Project Components/Inter-Coder Reliability/Data/Zhangzhuoran Dai/Training Data/Individual variable data/Number of strikes.csv")
number_of_strikes
```
Calculate ICC for two coders
```{r}
icc(number_of_strikes, #data frame
    model = "twoway", #two-way model selected as the selected raters are the only raters of interest (Koo & Li, 2016)
    type = "agreement", #absolute agreement between the raters to be calculated
    unit = "single", #measurement from a single rater as the basis of the actual measurement
    r0 = 0, #specification of the null hypothesis
    conf.level = 0.95) #confidence level
```
**ICC estimates and their 95% confidence intervals were calculated using R (v. 4.0.3) based on a single rater (k = 2), absolute-agreement, two-way mixed effects model. The ICC score indicated excellent reliability.** 

### Displacement rate

The variable *displacement rate* indicates the number of times a nut is hit off the anvil before the kernel is retrieved. This data is ratio, and so intraclass correlations (ICC) will be used to establish the reliability between two independent coders. In accordance with Koo & Li's (2016) guidelines on ICC model selection, the method used here will be a two-way, mixed-effects, single rater absolute agreement ICC.

Import data frame from csv file
```{r message=FALSE, warning=FALSE}
displacement_rate <- read_csv("~/Documents/Oxford/DPhil/Project Components/Inter-Coder Reliability/Data/Zhangzhuoran Dai/Training Data/Individual variable data/Displacement rate.csv")
displacement_rate
```

Calculate ICC for two coders
```{r}
icc(displacement_rate, #data frame
    model = "twoway", #two-way model selected as the selected raters are the only raters of interest (Koo & Li, 2016)
    type = "agreement", #absolute agreement between the raters to be calculated
    unit = "single", #measurement from a single rater as the basis of the actual measurement
    r0 = 0, #specification of the null hypothesis
    conf.level = 0.95) #confidence level
```
**ICC estimates and their 95% confidence intervals were calculated using R (v. 4.0.3) based on a single rater (k = 2), absolute-agreement, two-way mixed effects model. The ICC score indicated moderate reliability.** 

### Tool switch rate

The *tool switch rate* variable indicates when the focal individual changes one or both parts of the tool composite to a new tool or surface. This data is ratio, and so intraclass correlations (ICC) will be used to establish the reliability between two independent coders. In accordance with Koo & Li's (2016) guidelines on ICC model selection, the method used here will be a two-way, mixed-effects, single rater absolute agreement ICC.

Import data frame from csv file
```{r message=FALSE, warning=FALSE}
tool_switch_rate <- read_csv("~/Documents/Oxford/DPhil/Project Components/Inter-Coder Reliability/Data/Zhangzhuoran Dai/Training Data/Individual variable data/Tool switch rate.csv")
tool_switch_rate
```

Calculate ICC for two coders
```{r}
icc(tool_switch_rate, #data frame
    model = "twoway", #two-way model selected as the selected raters are the only raters of interest (Koo & Li, 2016)
    type = "agreement", #absolute agreement between the raters to be calculated
    unit = "single", #measurement from a single rater as the basis of the actual measurement
    r0 = 0, #specification of the null hypothesis
    conf.level = 0.95) #confidence level
```
**ICC estimates and their 95% confidence intervals were calculated using R (v. 4.0.3) based on a single rater (k = 2), absolute-agreement, two-way mixed effects model. The ICC score indicated perfect reliability.** 

### Bout duration

The variable **bout duration** indicates the length in seconds that the individual was continuously striking a nut with a hammer and anvil composite before the nut was either retrieved or was not retreived. This data is ratio, and so intraclass correlations (ICC) will be used to establish the reliability between two independent coders. In accordance with Koo & Li's (2016) guidelines on ICC model selection, the method used here will be a two-way, mixed-effects, single rater, consistency ICC.

Import data frame from csv file
```{r message=FALSE, warning=FALSE}
bout_duration <- read_csv("~/Documents/Oxford/DPhil/Project Components/Inter-Coder Reliability/Data/Zhangzhuoran Dai/Training Data/Individual variable data/Bout duration.csv")
bout_duration
```

Compute ICC for two coders
```{r}
icc(bout_duration, #data frame
    model = "twoway", #two-way model selected as the selected raters are the only raters of interest (Koo & Li, 2016)
    type = "consistency", #consistency between the raters to be calculated
    unit = "single", #measurement from a single rater as the basis of the actual measurement
    r0 = 0, #specification of the null hypothesis
    conf.level = 0.95) #confidence level
```

### Average strike duration

The variable **average strike** indicates the mean length in seconds that the individual was performing the strike action in a bout. This data is ratio, and so intraclass correlations (ICC) will be used to establish the reliability between two independent coders. In accordance with Koo & Li's (2016) guidelines on ICC model selection, the method used here will be a two-way, mixed-effects, single rater, consistency ICC.

Import data frame from csv file
```{r message=FALSE, warning=FALSE}
average_strike_duration <- read_csv("~/Documents/Oxford/DPhil/Project Components/Inter-Coder Reliability/Data/Zhangzhuoran Dai/Training Data/Individual variable data/Average strike duration.csv")
average_strike_duration
```

Compute ICC for two coders
```{r}
icc(average_strike_duration, #data frame
    model = "twoway", #two-way model selected as the selected raters are the only raters of interest (Koo & Li, 2016)
    type = "consistency", #consistency between the raters to be calculated
    unit = "single", #measurement from a single rater as the basis of the actual measurement
    r0 = 0, #specification of the null hypothesis
    conf.level = 0.95) #confidence level
```
**ICC estimates and their 95% confidence intervals were calculated using R (v. 4.0.3) based on a single rater (k = 2), consistency, two-way mixed effects model. The ICC score indicated moderate reliability.** 
